{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8cb6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b84e219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path.cwd().parent\n",
    "processed_dir = root_dir / \"data/artifacts\" / \"processed\"\n",
    "eq_df = pd.read_csv(processed_dir / \"EQ.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "583d2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index_name = \"groww-instruments-eq\"\n",
    "dimension = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c71bac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_indexes = [index.name for index in pc.list_indexes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d430d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new index: groww-instruments-eq\n"
     ]
    }
   ],
   "source": [
    "if index_name not in existing_indexes:\n",
    "    print(f\"Creating new index: {index_name}\")\n",
    "    pc.create_index_for_model(\n",
    "        name= index_name,\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\",\n",
    "        embed={\n",
    "            \"model\":\"llama-text-embed-v2\",\n",
    "            \"field_map\":{\"text\": \"chunk_text\"}\n",
    "        }\n",
    "    )\n",
    "else:\n",
    "    print(f\"Index {index_name} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7db579a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d1555e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embedding generated: 1024 dimensions\n"
     ]
    }
   ],
   "source": [
    "def get_openai_embedding(text: str, model: str = \"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Get embedding from OpenAI API\n",
    "    \n",
    "    Args:\n",
    "        text: Text to embed\n",
    "        model: OpenAI embedding model (default: text-embedding-3-large)\n",
    "    \n",
    "    Returns:\n",
    "        List of embedding values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=text,\n",
    "            model=model,\n",
    "            dimensions=dimension\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {e}\")\n",
    "        raise\n",
    "\n",
    "# Test the embedding function\n",
    "test_text = \"RELIANCE\"\n",
    "test_embedding = get_openai_embedding(test_text)\n",
    "print(f\"Test embedding generated: {len(test_embedding)} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb07cf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created searchable text for all records\n",
      "\n",
      "Sample searchable texts:\n",
      "['Sec Re NCD 10.50% Sr 6 | Symbol: 1050ISFL28 | Groww: NSE-1050ISFL28 | Exchange: NSE', '1015EFL29 | Symbol: 1015ECL29 | Groww: NSE-1015ECL29 | Exchange: NSE', 'UCL-10.25%-24-10-26-NCD | Symbol: 1025UCL26A | Groww: NSE-1025UCL26A | Exchange: NSE']\n"
     ]
    }
   ],
   "source": [
    "def create_searchable_text(row):\n",
    "    \"\"\"Create a searchable text string from row data\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    if pd.notna(row.get('name')):\n",
    "        parts.append(str(row['name']))\n",
    "    if pd.notna(row.get('trading_symbol')):\n",
    "        parts.append(f\"Symbol: {row['trading_symbol']}\")\n",
    "    if pd.notna(row.get('groww_symbol')):\n",
    "        parts.append(f\"Groww: {row['groww_symbol']}\")\n",
    "    if pd.notna(row.get('exchange')):\n",
    "        parts.append(f\"Exchange: {row['exchange']}\")\n",
    "    \n",
    "    return \" | \".join(parts)\n",
    "\n",
    "eq_df['searchable_text'] = eq_df.apply(create_searchable_text, axis=1)\n",
    "\n",
    "print(\"Created searchable text for all records\")\n",
    "print(\"\\nSample searchable texts:\")\n",
    "print(eq_df['searchable_text'].head(3).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dcd370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Generating embeddings for 12586 records using OpenAI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 126/126 [07:26<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Successfully uploaded 12586 vectors to Pinecone using OpenAI embeddings\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings in batches with rate limiting\n",
    "batch_size = 100\n",
    "vectors_to_upsert = []\n",
    "openai_batch_size = 100\n",
    "\n",
    "print(f\"ðŸ”„ Generating embeddings for {len(eq_df)} records using OpenAI...\")\n",
    "\n",
    "for batch_start in tqdm(range(0, len(eq_df), openai_batch_size), desc=\"Processing batches\"):\n",
    "    batch_end = min(batch_start + openai_batch_size, len(eq_df))\n",
    "    batch_df = eq_df.iloc[batch_start:batch_end]\n",
    "    \n",
    "    # Get embeddings for the batch\n",
    "    texts = batch_df['searchable_text'].tolist()\n",
    "    \n",
    "    try:\n",
    "        # Generate embeddings for the batch\n",
    "        response = client.embeddings.create(\n",
    "            input=texts,\n",
    "            model=\"text-embedding-3-large\",\n",
    "            dimensions=1024\n",
    "        )\n",
    "        \n",
    "        # Process each embedding\n",
    "        for idx, (row_idx, row) in enumerate(batch_df.iterrows()):\n",
    "            embedding = response.data[idx].embedding\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = {\n",
    "                'trading_symbol': str(row.get('trading_symbol', '')),\n",
    "                'groww_symbol': str(row.get('groww_symbol', '')),\n",
    "                'name': str(row.get('name', '')) if pd.notna(row.get('name')) else '',\n",
    "                'exchange': str(row.get('exchange', '')),\n",
    "                'instrument_type': str(row.get('instrument_type', '')),\n",
    "                'segment': str(row.get('segment', '')),\n",
    "                'searchable_text': row['searchable_text']\n",
    "            }\n",
    "            \n",
    "            # Add other non-null fields to metadata\n",
    "            for col in eq_df.columns:\n",
    "                if col not in ['searchable_text'] and pd.notna(row.get(col)):\n",
    "                    try:\n",
    "                        metadata[col] = str(row[col])\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            # Create vector record\n",
    "            vector_id = f\"eq_{row_idx}_{row.get('trading_symbol', row_idx)}\"\n",
    "            vectors_to_upsert.append({\n",
    "                'id': vector_id,\n",
    "                'values': embedding,\n",
    "                'metadata': metadata\n",
    "            })\n",
    "        \n",
    "        # Upsert to Pinecone in batches\n",
    "        if len(vectors_to_upsert) >= batch_size:\n",
    "            index.upsert(vectors=vectors_to_upsert)\n",
    "            vectors_to_upsert = []\n",
    "        \n",
    "        # Small delay to respect rate limits\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_start}-{batch_end}: {e}\")\n",
    "        # Continue with next batch\n",
    "        continue\n",
    "\n",
    "# Upsert remaining vectors\n",
    "if vectors_to_upsert:\n",
    "    index.upsert(vectors=vectors_to_upsert)\n",
    "\n",
    "print(f\"\\nSuccessfully uploaded {len(eq_df)} vectors to Pinecone using OpenAI embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "911b481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a64ab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Index Name: groww-instruments-eq\n",
      "   Total Vectors: 12586\n",
      "   Dimension: 1024\n",
      "   Index Fullness: 0.0\n",
      "   Namespaces: ['']\n"
     ]
    }
   ],
   "source": [
    "print(f\"   Index Name: {index_name}\")\n",
    "print(f\"   Total Vectors: {stats.total_vector_count}\")\n",
    "print(f\"   Dimension: {stats.dimension}\")\n",
    "print(f\"   Index Fullness: {stats.index_fullness}\")\n",
    "print(f\"   Namespaces: {list(stats.namespaces.keys())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


